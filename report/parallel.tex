\section*{Parallel division of the problem}

\subsection*{Parallel sections}
There were two key areas in which the process of deblurring the images could be divided up for parallel execution. The first and most obvious was that each image was completely independent of the others meaning that multiple images could be worked on in parallel. The second place the work could be made parallel was in the convolution of the images with the point spread function. This could be split up as the result of one pixel in an image being convoluted was independent of the results of the other pixels. Unlike the images however the result of a convolution of a pixel did depend on the value of neighbouring pixels. This meant that a problem occurred with how to split the image up.

\subsection*{Parallelisation overhead}
If an image was convoluted by an n by n point spread function, then to calculate the value of a pixel in the image \(n^2\) points of the image would need to be known. This presented a problem for a distributed system as it meant that if each pixel was to be calculated in its own process \(n^2\) pixels would have to be transferred to the process. This problem could be reduced by transferring blocks of pixels to each process for them to process however it would reduce the amount performed in parallel and still require additional transfer time when compared to one image per process.

The transfer of information could not be parallised and so this would increase the percent of the code that had to run in serial by a large amount. As according to Amdahl's law\cite{am} these sections of non-parallelisable code would have an extremely large impact on the runtime of the code the image convolution was not split up using MPI. This decision was made as it would have increased the runtime and only had the potential to offer any speed increase if there were more images to process then processors.

If the convolution is performed on a machine with multiple cores and shared memory (such as an OpenMP setup) however then no extra data transfers needs to take place as all the data is already present and so splitting up the image is a viable option.