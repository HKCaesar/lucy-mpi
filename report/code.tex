\section{Implemented code}

Two solutions were implemented one using MPI and one using OpenMP. The MPI solution sent one image out to each core of a processor in a distributed network where as the OpenMP solution operated by splittnig up each image when running on a single shared-memory machine. The MPI solution had the advantage of being able to run on a series of distributed machines and so able to use more cores to complete faster. The OpenMP solution had the advantage of less overhead in the form of transferring the data.

/subsection{MPI implementation}
The MPI solution worked by using the following steps.

\begin{enumerate}
	\item Create the master and n slave processes
	\item Load the psf from ./psf.bmp on the master computer
	\item Send the psf to all the slaves
	\item Get a list of all the images present on the master computer in ./Images/
	\item Send an image from the master to each of the slave processes.
	\item Each of the slaves processes the image using the Richardson-Lucy implemention.
	\item The master retrives the image from the slave and saves it to ./Output/
	\item The master sends the slave a new image
\end{enumerate}

In this implemention all the sending and receiving is done syncronsously with the exception of the retriving of the processed images from the slave. This retriving is made asyncronous so that if one of the slaves finishs faster then one that was started before it there is no delay as it waits for the slave before it to finish and send its image.

In the MPI implementaiton all the sending and receiving of images cannot be parrallized. The number of psfs that require sending also increases with the number of processors that are run. A test was conducted to find the time spent in these different sections by processing 16 1024 by 1024 pixel images  using a 3 by 3 psf.The computer used had a 2.0 GHz dual core proccssor and ran one master and one slave process.

The parrallized section took 386.98 seconds

The serilized section took 4.71 seconds

The total time was 391.69 seconds

Measuring the psf transfer times proved problematic as in the tests it was always less then 1 ms. This meant that even for 1000 process it would add less then 1 second of processing time and so the time increase in the serialized time due to it was ignored.

The above results show that 98.90 percent of the program was parrallizeable and to process all ten million images would require roughly 68000 hours of machine time to complete or 2833 days.

Using armdales law the speed up of the process can be given by
\[
 \frac{1}{(1-P) + \frac{P}{S}}
\]

Where P is the amount of parrallizable code (98.90\% in this case) and S is the number of processors. The amount of time in days to complete the calculation can be shown in Figure~\ref{mpi-time-cores}. As can be obsereved the time for one core is 2833 days, ten cores take 310 days, 20 cores take 171 days, 50 cores take 90 days and 100 cores take 58 days. Beyond this point the speed up from additional cores becomes negligible as the unparralizable sections of code take 31 days to execute. 

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=1.0\textwidth]{mpi-time-cores}
	\end{center}
	\caption{Graph showing time to process vs number of cores for the MPI solution}
	\label{mpi-time-cores}
\end{figure}

For running the system the hardware required has to either be rented or brought. A desktop unit with four 3.0 GHz cores costs around \$1000 dollars. For rent the Amazon EC2 service appeared to be the cheapest of the avalibale options charging \$0.68 per hour for use of the High-CPU Extra Large Instance which provideds the following 

\begin{itemize}
\item 7 GB of memory
\item 20 EC2 Compute Units (8 virtual cores with 2.5 EC2 Compute Units each)
\item 1690 GB of instance storage
\item 64-bit platform
\item I/O Performance: High (1 GigaBit ethernet)
\end{itemize}

The EC2 compute units the performance is measured in is equivalent to a 1.0-1.2 GHz 2007 Opteron or 2007 Xeon processor. These processors have roughly 60\% of the processing power of one of the test computers cores. From this information the cost of hiring and buying can be calculated for a set time in which the task has to be completed. This is shown in Figure~\ref{mpi-time-money}. Times below 40 days were not shown as the costs quickly became totally infesable. It can be noted that for processing times longer then 100 days buying units becomes more economical then renting thanks to the one off cost rather then the cost per hour for the cpu time. It should be motioned that the cloud also offers 1 year of use for the much reduced price of \$1820.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=1.0\textwidth]{mpi-time-money}
	\end{center}
	\caption{Cost comparision for the MPI solution taking into account time to complete}
	\label{mpi-time-money}
\end{figure}

\subsection{OpenMP implementation}
The OpenMP solution worked by using the following steps.

\begin{enumerate}
	\item Load the psf from ./psf.bmp
	\item Get a list of all the images present in ./Images/
	\item load the first image
	\item run the image using the Richardson-Lucy implemention.
	\item Saves the output to ./Output/
	\item Get the next image
\end{enumerate}

The parallelization of this program occoured in two places. First during the choosing of the image to run the Richardson-Lucy algorithem on and secondly during the convolutions. The Lucy-Richardson algorithem was written so that it used a series of for loops for the convolutions rather then a convolution function (such as that provided by the CImg libraries). This meant that for each pixel and colour channel the value could be found in its own thread and combined at the end of the convolution running potentially up to 1024x1024x3 threads. As was done with the MPI implementation a test was conducted to find the time spent in the parrallel and serial sections by processing 16 1024 by 1024 pixel images  using a 3 by 3 psf.

The parrallized section took 370.86 seconds

The serilized section took 4.90 seconds

The total time was 375.6 seconds

These results were suprising for two reasons. Firstly the serilized parts of the code was only marginally shorter then in the MPI implementation. This shows that most of the time spent in this section must be due to the loading of images from the hard drive and not the transfering of them in MPI as was initally belivied. The second suprising aspect was that the OpenMP run time was significantly shorter then the MPI programs run time. This must mean that in the parrallel sections MPI has some overhead on each image causing it to run on average 0.99 seconds slower per image or 6.2\%. Thus in this case to process 10 million images would take 65236 hours or 2718 days of processing time with 98.7\% being parralelzable. Again armsdale law was applied with the results plotted in Figure~\ref{opm-time-cores}. This figure was very similar to the one found for MPI.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=1.0\textwidth]{mpi-time-cores}
	\end{center}
	\caption{Graph showing time to process vs number of cores for the OpenMP solution}
	\label{mpi-time-cores}
\end{figure}

When the price of the system was considered the shared memeory requirement of OpenMP has to be taken into account. For a system with mulitple CPUs on one motherboard the price increases sharply. One 3 GHz quad-core processor system cost roughly \$1000, two processor cost \$4000, three processor cost \$15000 and four processors cost roughly \$50000. This cost and the run time for these systems is shown in Figure~\ref{omp-time-money}.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[width=1.0\textwidth]{mpi-time-money}
	\end{center}
	\caption{Cost comparision for the Open solution taking into account time to complete}
	\label{mpi-time-money}
\end{figure}


\subsection{Comparison of Methods}

When the cost vs time of the two graphs are overlaid (taking the most cost effective method for the MPI solution) the difference in price of the two methods becomes clear. This is show in Figure~
